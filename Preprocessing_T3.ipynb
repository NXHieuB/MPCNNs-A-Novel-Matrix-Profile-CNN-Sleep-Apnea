{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17b76299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import biosppy.signals.tools as st\n",
    "import numpy as np\n",
    "import os\n",
    "import wfdb\n",
    "from biosppy.signals.ecg import correct_rpeaks, hamilton_segmenter\n",
    "from scipy.signal import medfilt\n",
    "from multiprocessing import cpu_count\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import cheby2, filtfilt\n",
    "\n",
    "# PhysioNet Apnea-ECG dataset\n",
    "# url: https://physionet.org/physiobank/database/apnea-ecg/\n",
    "base_dir = \"dataset\"\n",
    "\n",
    "fs = 100\n",
    "sample = fs * 60  # 1 min's sample points\n",
    "\n",
    "before = 2  # forward interval (min)\n",
    "after = 2  # backward interval (min)\n",
    "hr_min = 20\n",
    "hr_max = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd1572f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_p_peaks(ecg_signal, r_peaks, search_window=20, exclude_window=5):\n",
    "    \"\"\"\n",
    "    Finds the P peaks in an ECG signal.\n",
    "\n",
    "    Parameters:\n",
    "        ecg_signal (numpy.ndarray): The ECG signal.\n",
    "        r_peaks (numpy.ndarray): The indices of R peaks in the ECG signal.\n",
    "        search_window (int, optional): The number of samples to look for the P wave peak before each R peak.\n",
    "        exclude_window (int, optional): The number of samples to exclude immediately before the R peak.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The indices of the P peaks.\n",
    "    \"\"\"\n",
    "\n",
    "    p_peaks = []\n",
    "\n",
    "    for r_peak in r_peaks:\n",
    "        # Ensure that the search window does not go beyond the start of the signal\n",
    "        search_start = max(0, r_peak - search_window)\n",
    "        # Exclude a certain window immediately before the R peak\n",
    "        search_end = max(0, r_peak - exclude_window)\n",
    "\n",
    "        # Search for the maximum point in the search window, which is assumed to be the P peak.\n",
    "        p_peak_relative = np.argmax(ecg_signal[search_start:search_end])\n",
    "\n",
    "        # Add the search start index to get the absolute index in the ECG signal.\n",
    "        p_peak_absolute = p_peak_relative + search_start\n",
    "\n",
    "        p_peaks.append(p_peak_absolute)\n",
    "\n",
    "    return p_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7da7070",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_q_peaks(ecg_signal, r_peaks, search_window=20, exclude_window=0):\n",
    "    \"\"\"\n",
    "    Finds the P peaks in an ECG signal.\n",
    "\n",
    "    Parameters:\n",
    "        ecg_signal (numpy.ndarray): The ECG signal.\n",
    "        r_peaks (numpy.ndarray): The indices of R peaks in the ECG signal.\n",
    "        search_window (int, optional): The number of samples to look for the P wave peak before each R peak.\n",
    "        exclude_window (int, optional): The number of samples to exclude immediately before the R peak.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The indices of the P peaks.\n",
    "    \"\"\"\n",
    "\n",
    "    p_peaks = []\n",
    "\n",
    "    for r_peak in r_peaks:\n",
    "        # Ensure that the search window does not go beyond the start of the signal\n",
    "        search_start = max(0, r_peak - search_window)\n",
    "        # Exclude a certain window immediately before the R peak\n",
    "        search_end = max(0, r_peak - exclude_window)\n",
    "\n",
    "        # Search for the maximum point in the search window, which is assumed to be the P peak.\n",
    "        p_peak_relative = np.argmin(ecg_signal[search_start:search_end])\n",
    "\n",
    "        # Add the search start index to get the absolute index in the ECG signal.\n",
    "        p_peak_absolute = p_peak_relative + search_start\n",
    "\n",
    "        p_peaks.append(p_peak_absolute)\n",
    "\n",
    "    return p_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42b15ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(arr1, arr2):\n",
    "    return np.linalg.norm(arr1 - arr2)\n",
    "def min_max_normalize(lst):\n",
    "    minimum = min(lst)\n",
    "    maximum = max(lst)\n",
    "    normalized_lst = [(x - minimum) / (maximum - minimum) for x in lst]\n",
    "    return normalized_lst\n",
    "def worker(name, labels):\n",
    "    X = []\n",
    "    y = []\n",
    "    groups = []\n",
    "    signals = wfdb.rdrecord(os.path.join(base_dir, name), channels=[0]).p_signal[:, 0]\n",
    "    for j in tqdm(range(len(labels)), desc=name, file=sys.stdout):\n",
    "        if j < before or (j + 1 + after) > len(signals) / float(sample):\n",
    "            continue\n",
    "        signal = signals[int((j - before) * sample):int((j + 1 + after) * sample)]\n",
    "        signal, _, _ = st.filter_signal(signal, ftype='FIR', band='bandpass', order=int(0.3 * fs),\n",
    "                                        frequency=[3, 45], sampling_rate=fs)\n",
    "        # Find R peaks\n",
    "        rpeaks, = hamilton_segmenter(signal, sampling_rate=fs)\n",
    "        rpeaks, = correct_rpeaks(signal, rpeaks=rpeaks, sampling_rate=fs, tol=0.1)\n",
    "        #Remove the rpeak with unexpected value\n",
    "        mask = (rpeaks <= 29950)\n",
    "        rpeaks = rpeaks[mask]\n",
    "        if len(rpeaks) / (1 + after + before) < 40 or len(rpeaks) / (1 + after + before) > 200:\n",
    "            continue\n",
    "        #Find P peaks\n",
    "        qpeaks = find_q_peaks(signal, rpeaks,20,0)\n",
    "        #Extract the information\n",
    "        new_signal = []\n",
    "        #T_3 case\n",
    "        for value in qpeaks:\n",
    "            new_signal.append(signal[int(value): int(value) + 39])\n",
    "\n",
    "        min_distance_list = []\n",
    "        max_distance_list = []\n",
    "        all_distances_list = []\n",
    "\n",
    "        for element_1 in range(len(new_signal)):\n",
    "            base_array = new_signal[element_1]\n",
    "            min_distance = np.inf\n",
    "            max_distance = -np.inf\n",
    "            distances = []\n",
    "\n",
    "            for element_2 in range(len(new_signal)):\n",
    "                if element_1 != element_2:\n",
    "                    distance = euclidean_distance(base_array, new_signal[element_2])\n",
    "                    distances.append(distance)\n",
    "\n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                    if distance > max_distance:\n",
    "                        max_distance = distance\n",
    "\n",
    "            min_distance_list.append(min_distance)\n",
    "            max_distance_list.append(max_distance)\n",
    "            all_distances_list.append(distances)\n",
    "\n",
    "        mean_distance_list = [np.mean(distances) for distances in all_distances_list]\n",
    "\n",
    "        min_distance_list = min_max_normalize(min_distance_list)\n",
    "        max_distance_list = min_max_normalize(max_distance_list)\n",
    "        mean_distance_list = min_max_normalize(mean_distance_list)\n",
    "\n",
    "        hr_coefficient = np.diff(rpeaks) / float(fs)\n",
    "        hr_coefficient = medfilt(hr_coefficient, kernel_size=3)\n",
    "        hr = 60 / hr_coefficient\n",
    "        min_distance_list = np.array(min_distance_list)\n",
    "        max_distance_list = np.array(max_distance_list)\n",
    "        mean_distance_list = np.array(mean_distance_list)\n",
    "        # Remove physiologically impossible HR signal \n",
    "        if np.all(np.logical_and(hr >= hr_min, hr <= hr_max)):\n",
    "            # Save extracted signal\n",
    "            X.append([min_distance_list,max_distance_list, mean_distance_list])\n",
    "            y.append(0. if labels[j] == 'N' else 1.)\n",
    "            groups.append(name)\n",
    "    return X, y, groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec9a538a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "a01: 100%|██████████| 489/489 [02:59<00:00,  2.73it/s]\n",
      "a02: 100%|██████████| 528/528 [05:13<00:00,  1.68it/s]\n",
      "a03: 100%|██████████| 519/519 [03:28<00:00,  2.49it/s]\n",
      "a04: 100%|██████████| 492/492 [03:05<00:00,  2.65it/s]\n",
      "a05: 100%|██████████| 454/454 [02:58<00:00,  2.54it/s]\n",
      "a06: 100%|██████████| 510/510 [04:23<00:00,  1.93it/s]\n",
      "a07: 100%|██████████| 511/511 [04:56<00:00,  1.72it/s]\n",
      "a08: 100%|██████████| 501/501 [05:58<00:00,  1.40it/s]\n",
      "a09: 100%|██████████| 495/495 [03:55<00:00,  2.10it/s]\n",
      "a10: 100%|██████████| 517/517 [03:58<00:00,  2.17it/s]\n",
      "a11: 100%|██████████| 466/466 [04:29<00:00,  1.73it/s]\n",
      "a12: 100%|██████████| 577/577 [04:29<00:00,  2.14it/s]\n",
      "a13: 100%|██████████| 495/495 [05:06<00:00,  1.61it/s]\n",
      "a14: 100%|██████████| 509/509 [02:39<00:00,  3.18it/s]\n",
      "a15: 100%|██████████| 510/510 [03:34<00:00,  2.38it/s]\n",
      "a16: 100%|██████████| 482/482 [03:46<00:00,  2.13it/s]\n",
      "a17: 100%|██████████| 485/485 [04:11<00:00,  1.93it/s]\n",
      "a18: 100%|██████████| 489/489 [02:58<00:00,  2.75it/s]\n",
      "a19: 100%|██████████| 502/502 [04:21<00:00,  1.92it/s]\n",
      "a20: 100%|██████████| 510/510 [03:35<00:00,  2.36it/s]\n",
      "b01: 100%|██████████| 487/487 [03:50<00:00,  2.11it/s]\n",
      "b02: 100%|██████████| 517/517 [03:32<00:00,  2.44it/s]\n",
      "b03: 100%|██████████| 441/441 [02:58<00:00,  2.47it/s]\n",
      "b04: 100%|██████████| 429/429 [02:25<00:00,  2.95it/s]\n",
      "b05: 100%|██████████| 433/433 [02:50<00:00,  2.53it/s]\n",
      "c01: 100%|██████████| 484/484 [02:42<00:00,  2.97it/s]\n",
      "c02: 100%|██████████| 502/502 [03:18<00:00,  2.53it/s]\n",
      "c03: 100%|██████████| 454/454 [02:09<00:00,  3.49it/s]\n",
      "c04: 100%|██████████| 482/482 [03:01<00:00,  2.66it/s]\n",
      "c05: 100%|██████████| 466/466 [02:45<00:00,  2.82it/s]\n",
      "c06: 100%|██████████| 468/468 [02:46<00:00,  2.82it/s]\n",
      "c07: 100%|██████████| 429/429 [03:32<00:00,  2.02it/s]\n",
      "c08: 100%|██████████| 513/513 [03:03<00:00,  2.80it/s]\n",
      "c09: 100%|██████████| 468/468 [03:24<00:00,  2.29it/s]\n",
      "c10: 100%|██████████| 431/431 [02:17<00:00,  3.13it/s]\n",
      "\n",
      "Testing...\n",
      "x01: 100%|██████████| 523/523 [04:04<00:00,  2.14it/s]\n",
      "x02: 100%|██████████| 469/469 [04:49<00:00,  1.62it/s]\n",
      "x03: 100%|██████████| 465/465 [03:40<00:00,  2.11it/s]\n",
      "x04: 100%|██████████| 482/482 [02:22<00:00,  3.38it/s]\n",
      "x05: 100%|██████████| 505/505 [03:45<00:00,  2.24it/s]\n",
      "x06: 100%|██████████| 450/450 [01:58<00:00,  3.79it/s]\n",
      "x07: 100%|██████████| 509/509 [03:11<00:00,  2.66it/s]\n",
      "x08: 100%|██████████| 517/517 [03:49<00:00,  2.26it/s]\n",
      "x09: 100%|██████████| 508/508 [04:14<00:00,  1.99it/s]\n",
      "x10: 100%|██████████| 510/510 [04:57<00:00,  1.71it/s]\n",
      "x11: 100%|██████████| 457/457 [03:06<00:00,  2.45it/s]\n",
      "x12: 100%|██████████| 527/527 [04:24<00:00,  2.00it/s]\n",
      "x13: 100%|██████████| 506/506 [04:19<00:00,  1.95it/s]\n",
      "x14: 100%|██████████| 490/490 [05:11<00:00,  1.58it/s]\n",
      "x15: 100%|██████████| 498/498 [03:11<00:00,  2.61it/s]\n",
      "x16: 100%|██████████| 515/515 [03:35<00:00,  2.39it/s]\n",
      "x17: 100%|██████████| 400/400 [01:41<00:00,  3.94it/s]\n",
      "x18: 100%|██████████| 459/459 [02:23<00:00,  3.20it/s]\n",
      "x19: 100%|██████████| 487/487 [03:08<00:00,  2.59it/s]\n",
      "x20: 100%|██████████| 513/513 [04:33<00:00,  1.88it/s]\n",
      "x21: 100%|██████████| 510/510 [03:23<00:00,  2.50it/s]\n",
      "x22: 100%|██████████| 482/482 [02:56<00:00,  2.73it/s]\n",
      "x23: 100%|██████████| 527/527 [04:11<00:00,  2.10it/s]\n",
      "x24: 100%|██████████| 429/429 [02:07<00:00,  3.36it/s]\n",
      "x25: 100%|██████████| 510/510 [03:58<00:00,  2.14it/s]\n",
      "x26: 100%|██████████| 520/520 [03:17<00:00,  2.63it/s]\n",
      "x27: 100%|██████████| 498/498 [04:44<00:00,  1.75it/s]\n",
      "x28: 100%|██████████| 495/495 [04:38<00:00,  1.77it/s]\n",
      "x29: 100%|██████████| 470/470 [03:10<00:00,  2.47it/s]\n",
      "x30: 100%|██████████| 511/511 [03:59<00:00,  2.14it/s]\n",
      "x31: 100%|██████████| 557/557 [03:27<00:00,  2.68it/s]\n",
      "x32: 100%|██████████| 538/538 [03:31<00:00,  2.54it/s]\n",
      "x33: 100%|██████████| 473/473 [03:48<00:00,  2.07it/s]\n",
      "x34: 100%|██████████| 475/475 [03:49<00:00,  2.07it/s]\n",
      "x35: 100%|██████████| 483/483 [02:59<00:00,  2.69it/s]\n",
      "\n",
      "ok!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    apnea_ecg = {}\n",
    "\n",
    "    names = [\n",
    "        \"a01\", \"a02\", \"a03\", \"a04\", \"a05\", \"a06\", \"a07\", \"a08\", \"a09\", \"a10\",\n",
    "        \"a11\", \"a12\", \"a13\", \"a14\", \"a15\", \"a16\", \"a17\", \"a18\", \"a19\", \"a20\",\n",
    "        \"b01\", \"b02\", \"b03\", \"b04\", \"b05\",\n",
    "        \"c01\", \"c02\", \"c03\", \"c04\", \"c05\", \"c06\", \"c07\", \"c08\", \"c09\", \"c10\"\n",
    "    ]\n",
    "\n",
    "    o_train = []\n",
    "    y_train = []\n",
    "    groups_train = []\n",
    "    print('Training...')\n",
    "    for i in range(len(names)):\n",
    "        labels = wfdb.rdann(os.path.join(base_dir, names[i]), extension=\"apn\").symbol\n",
    "        X, y, groups = worker(names[i], labels)\n",
    "        o_train.extend(X)\n",
    "        y_train.extend(y)\n",
    "        groups_train.extend(groups)\n",
    "\n",
    "    print()\n",
    "\n",
    "    answers = {}\n",
    "    with open(os.path.join(base_dir, \"event-2-answers.txt\"), \"r\") as f:\n",
    "        for answer in f.read().split(\"\\n\\n\"):\n",
    "            answers[answer[:3]] = list(\"\".join(answer.split()[2::2]))\n",
    "\n",
    "    names = [\n",
    "        \"x01\", \"x02\", \"x03\", \"x04\", \"x05\", \"x06\", \"x07\", \"x08\", \"x09\", \"x10\",\n",
    "        \"x11\", \"x12\", \"x13\", \"x14\", \"x15\", \"x16\", \"x17\", \"x18\", \"x19\", \"x20\",\n",
    "        \"x21\", \"x22\", \"x23\", \"x24\", \"x25\", \"x26\", \"x27\", \"x28\", \"x29\", \"x30\",\n",
    "        \"x31\", \"x32\", \"x33\", \"x34\", \"x35\"\n",
    "    ]\n",
    "\n",
    "    o_test = []\n",
    "    y_test = []\n",
    "    groups_test = []\n",
    "    print(\"Testing...\")\n",
    "    for i in range(len(names)):\n",
    "        labels = answers[names[i]]\n",
    "        X, y, groups = worker(names[i], labels)\n",
    "        o_test.extend(X)\n",
    "        y_test.extend(y)\n",
    "        groups_test.extend(groups)\n",
    "\n",
    "    apnea_ecg = dict(\n",
    "        o_train=o_train, y_train=y_train, groups_train=groups_train,\n",
    "        o_test=o_test, y_test=y_test, groups_test=groups_test\n",
    "    )\n",
    "    with open(os.path.join(base_dir, \"T_3.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(apnea_ecg, f, protocol=2)\n",
    "\n",
    "    print(\"\\nok!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a84d68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
