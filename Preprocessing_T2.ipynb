{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17b76299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "import biosppy.signals.tools as st\n",
    "import numpy as np\n",
    "import os\n",
    "import wfdb\n",
    "from biosppy.signals.ecg import correct_rpeaks, hamilton_segmenter\n",
    "from scipy.signal import medfilt\n",
    "from multiprocessing import cpu_count\n",
    "from tqdm import tqdm\n",
    "from scipy.signal import cheby2, filtfilt\n",
    "\n",
    "# PhysioNet Apnea-ECG dataset\n",
    "# url: https://physionet.org/physiobank/database/apnea-ecg/\n",
    "base_dir = \"dataset\"\n",
    "\n",
    "fs = 100\n",
    "sample = fs * 60  # 1 min's sample points\n",
    "\n",
    "before = 2  # forward interval (min)\n",
    "after = 2  # backward interval (min)\n",
    "hr_min = 20\n",
    "hr_max = 300\n",
    "\n",
    "num_worker = 35 if cpu_count() > 35 else cpu_count() - 1  # Setting according to the number of CPU cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd1572f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_p_peaks(ecg_signal, r_peaks, search_window=20, exclude_window=5):\n",
    "    \"\"\"\n",
    "    Finds the P peaks in an ECG signal.\n",
    "\n",
    "    Parameters:\n",
    "        ecg_signal (numpy.ndarray): The ECG signal.\n",
    "        r_peaks (numpy.ndarray): The indices of R peaks in the ECG signal.\n",
    "        search_window (int, optional): The number of samples to look for the P wave peak before each R peak.\n",
    "        exclude_window (int, optional): The number of samples to exclude immediately before the R peak.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The indices of the P peaks.\n",
    "    \"\"\"\n",
    "\n",
    "    p_peaks = []\n",
    "\n",
    "    for r_peak in r_peaks:\n",
    "        # Ensure that the search window does not go beyond the start of the signal\n",
    "        search_start = max(0, r_peak - search_window)\n",
    "        # Exclude a certain window immediately before the R peak\n",
    "        search_end = max(0, r_peak - exclude_window)\n",
    "\n",
    "        # Search for the maximum point in the search window, which is assumed to be the P peak.\n",
    "        p_peak_relative = np.argmax(ecg_signal[search_start:search_end])\n",
    "\n",
    "        # Add the search start index to get the absolute index in the ECG signal.\n",
    "        p_peak_absolute = p_peak_relative + search_start\n",
    "\n",
    "        p_peaks.append(p_peak_absolute)\n",
    "\n",
    "    return p_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42b15ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(arr1, arr2):\n",
    "    return np.linalg.norm(arr1 - arr2)\n",
    "def min_max_normalize(lst):\n",
    "    minimum = min(lst)\n",
    "    maximum = max(lst)\n",
    "    normalized_lst = [(x - minimum) / (maximum - minimum) for x in lst]\n",
    "    return normalized_lst\n",
    "def worker(name, labels):\n",
    "    X = []\n",
    "    y = []\n",
    "    groups = []\n",
    "    signals = wfdb.rdrecord(os.path.join(base_dir, name), channels=[0]).p_signal[:, 0]\n",
    "    for j in tqdm(range(len(labels)), desc=name, file=sys.stdout):\n",
    "        if j < before or (j + 1 + after) > len(signals) / float(sample):\n",
    "            continue\n",
    "        signal = signals[int((j - before) * sample):int((j + 1 + after) * sample)]\n",
    "        signal, _, _ = st.filter_signal(signal, ftype='FIR', band='bandpass', order=int(0.3 * fs),\n",
    "                                        frequency=[3, 45], sampling_rate=fs)\n",
    "        # Find R peaks\n",
    "        rpeaks, = hamilton_segmenter(signal, sampling_rate=fs)\n",
    "        rpeaks, = correct_rpeaks(signal, rpeaks=rpeaks, sampling_rate=fs, tol=0.1)\n",
    "        #Remove the rpeak with unexpected value\n",
    "        mask = (rpeaks <= 29950) & (rpeaks >=50)\n",
    "        rpeaks = rpeaks[mask]\n",
    "        if len(rpeaks) / (1 + after + before) < 40 or len(rpeaks) / (1 + after + before) > 200:\n",
    "            continue\n",
    "        #Find P peaks\n",
    "        ppeaks = find_p_peaks(signal, rpeaks,20,5)\n",
    "        #Extract the information\n",
    "        new_signal = []\n",
    "        #T_2 case\n",
    "        for value in ppeaks:\n",
    "            new_signal.append(signal[int(value): int(value) + 28])\n",
    "\n",
    "        min_distance_list = []\n",
    "        max_distance_list = []\n",
    "        all_distances_list = []\n",
    "\n",
    "        for element_1 in range(len(new_signal)):\n",
    "            base_array = new_signal[element_1]\n",
    "            min_distance = np.inf\n",
    "            max_distance = -np.inf\n",
    "            distances = []\n",
    "\n",
    "            for element_2 in range(len(new_signal)):\n",
    "                if element_1 != element_2:\n",
    "                    distance = euclidean_distance(base_array, new_signal[element_2])\n",
    "                    distances.append(distance)\n",
    "\n",
    "                    if distance < min_distance:\n",
    "                        min_distance = distance\n",
    "                    if distance > max_distance:\n",
    "                        max_distance = distance\n",
    "\n",
    "            min_distance_list.append(min_distance)\n",
    "            max_distance_list.append(max_distance)\n",
    "            all_distances_list.append(distances)\n",
    "\n",
    "        mean_distance_list = [np.mean(distances) for distances in all_distances_list]\n",
    "\n",
    "        min_distance_list = min_max_normalize(min_distance_list)\n",
    "        max_distance_list = min_max_normalize(max_distance_list)\n",
    "        mean_distance_list = min_max_normalize(mean_distance_list)\n",
    "\n",
    "        hr_coefficient = np.diff(rpeaks) / float(fs)\n",
    "        hr_coefficient = medfilt(hr_coefficient, kernel_size=3)\n",
    "        hr = 60 / hr_coefficient\n",
    "        min_distance_list = np.array(min_distance_list)\n",
    "        max_distance_list = np.array(max_distance_list)\n",
    "        mean_distance_list = np.array(mean_distance_list)\n",
    "        # Remove physiologically impossible HR signal \n",
    "        if np.all(np.logical_and(hr >= hr_min, hr <= hr_max)):\n",
    "            # Save extracted signal\n",
    "            X.append([min_distance_list,max_distance_list, mean_distance_list])\n",
    "            y.append(0. if labels[j] == 'N' else 1.)\n",
    "            groups.append(name)\n",
    "    return X, y, groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a84d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    apnea_ecg = {}\n",
    "\n",
    "    names = [\n",
    "        \"a01\", \"a02\", \"a03\", \"a04\", \"a05\", \"a06\", \"a07\", \"a08\", \"a09\", \"a10\",\n",
    "        \"a11\", \"a12\", \"a13\", \"a14\", \"a15\", \"a16\", \"a17\", \"a18\", \"a19\", \"a20\",\n",
    "        \"b01\", \"b02\", \"b03\", \"b04\", \"b05\",\n",
    "        \"c01\", \"c02\", \"c03\", \"c04\", \"c05\", \"c06\", \"c07\", \"c08\", \"c09\", \"c10\"\n",
    "    ]\n",
    "\n",
    "    o_train = []\n",
    "    y_train = []\n",
    "    groups_train = []\n",
    "    print('Training...')\n",
    "    for i in range(len(names)):\n",
    "        labels = wfdb.rdann(os.path.join(base_dir, names[i]), extension=\"apn\").symbol\n",
    "        X, y, groups = worker(names[i], labels)\n",
    "        o_train.extend(X)\n",
    "        y_train.extend(y)\n",
    "        groups_train.extend(groups)\n",
    "\n",
    "    print()\n",
    "\n",
    "    answers = {}\n",
    "    with open(os.path.join(base_dir, \"event-2-answers.txt\"), \"r\") as f:\n",
    "        for answer in f.read().split(\"\\n\\n\"):\n",
    "            answers[answer[:3]] = list(\"\".join(answer.split()[2::2]))\n",
    "\n",
    "    names = [\n",
    "        \"x01\", \"x02\", \"x03\", \"x04\", \"x05\", \"x06\", \"x07\", \"x08\", \"x09\", \"x10\",\n",
    "        \"x11\", \"x12\", \"x13\", \"x14\", \"x15\", \"x16\", \"x17\", \"x18\", \"x19\", \"x20\",\n",
    "        \"x21\", \"x22\", \"x23\", \"x24\", \"x25\", \"x26\", \"x27\", \"x28\", \"x29\", \"x30\",\n",
    "        \"x31\", \"x32\", \"x33\", \"x34\", \"x35\"\n",
    "    ]\n",
    "\n",
    "    o_test = []\n",
    "    y_test = []\n",
    "    groups_test = []\n",
    "    print(\"Testing...\")\n",
    "    for i in range(len(names)):\n",
    "        labels = answers[names[i]]\n",
    "        X, y, groups = worker(names[i], labels)\n",
    "        o_test.extend(X)\n",
    "        y_test.extend(y)\n",
    "        groups_test.extend(groups)\n",
    "\n",
    "    apnea_ecg = dict(\n",
    "        o_train=o_train, y_train=y_train, groups_train=groups_train,\n",
    "        o_test=o_test, y_test=y_test, groups_test=groups_test\n",
    "    )\n",
    "    with open(os.path.join(base_dir, \"T_2.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(apnea_ecg, f, protocol=2)\n",
    "\n",
    "    print(\"\\nok!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
